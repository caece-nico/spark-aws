{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering \n",
    "\n",
    "### For movie recommenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count\n",
    "from pyspark.sql.types import StructField, StructType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Cargamos los DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/01 16:33:15 WARN Utils: Your hostname, DESKTOP-SLEQT56 resolves to a loopback address: 127.0.1.1; using 172.25.13.138 instead (on interface eth0)\n",
      "24/04/01 16:33:15 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/01 16:33:17 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/04/01 16:33:18 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.\\\n",
    "    master(\"local\").\\\n",
    "        appName(\"collabFilter\").\\\n",
    "            getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie = spark.read.options(header='True', inferSchema='True').csv(\"/mnt/d/Proyectos/Tutorial-SparkAWS/collaborative_data/movies.csv\")\n",
    "df_rating = spark.read.options(header='True', inferSchema='True').csv(\"/mnt/d/Proyectos/Tutorial-SparkAWS/collaborative_data/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+--------------------+\n",
      "|movieId|           title|              genres|\n",
      "+-------+----------------+--------------------+\n",
      "|      1|Toy Story (1995)|Adventure|Animati...|\n",
      "|      2|  Jumanji (1995)|Adventure|Childre...|\n",
      "+-------+----------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------+-------+------+---------+\n",
      "|userId|movieId|rating|timestamp|\n",
      "+------+-------+------+---------+\n",
      "|     1|      1|   4.0|964982703|\n",
      "|     1|      3|   4.0|964981247|\n",
      "+------+-------+------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_movie.show(2)\n",
    "df_rating.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: integer (nullable = true)\n",
      " |-- movieId: integer (nullable = true)\n",
      " |-- rating: double (nullable = true)\n",
      " |-- timestamp: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rating.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Joining DataFrames "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+---------+--------------------+--------------------+\n",
      "|movieId|userId|rating|timestamp|               title|              genres|\n",
      "+-------+------+------+---------+--------------------+--------------------+\n",
      "|      1|     1|   4.0|964982703|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      3|     1|   4.0|964981247|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      6|     1|   4.0|964982224|         Heat (1995)|Action|Crime|Thri...|\n",
      "+-------+------+------+---------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rating.join(df_movie, on='movieId', how = 'inner').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+---------+--------------------+--------------------+\n",
      "|movieId|userId|rating|timestamp|               title|              genres|\n",
      "+-------+------+------+---------+--------------------+--------------------+\n",
      "|      1|     1|   4.0|964982703|    Toy Story (1995)|Adventure|Animati...|\n",
      "|      3|     1|   4.0|964981247|Grumpier Old Men ...|      Comedy|Romance|\n",
      "|      6|     1|   4.0|964982224|         Heat (1995)|Action|Crime|Thri...|\n",
      "|     47|     1|   5.0|964983815|Seven (a.k.a. Se7...|    Mystery|Thriller|\n",
      "+-------+------+------+---------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final = df_rating.join(df_movie, on = \"movieId\", how = \"inner\")\n",
    "df_final.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Controlamos que no haya duplicados__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+\n",
      "|movieId|userId|miCount|\n",
      "+-------+------+-------+\n",
      "+-------+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_final.groupBy(col(\"movieId\"), col(\"userId\")).\\\n",
    "    agg(count(col(\"movieId\")).alias('miCount')).\\\n",
    "        filter(col('miCount')> 1).\\\n",
    "            show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Hacemos Split de los datos 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = df_final.randomSplit([.8, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------+----------+----------------+--------------------+\n",
      "|movieId|userId|rating| timestamp|           title|              genres|\n",
      "+-------+------+------+----------+----------------+--------------------+\n",
      "|      1|     5|   4.0| 847434962|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|     7|   4.5|1106635946|Toy Story (1995)|Adventure|Animati...|\n",
      "|      1|    15|   2.5|1510577970|Toy Story (1995)|Adventure|Animati...|\n",
      "+-------+------+------+----------+----------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80749"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.show(3)\n",
    "df_train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Creacion de modelo ASL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\", \n",
    "nonnegative=True, implicitPrefs=False, coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Tuning del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1.1 creamos el grid con 16 modelos posibles__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder()\\\n",
    "    .addGrid(als.rank, [10, 50, 100, 150])\\\n",
    "    .addGrid(als.regParam, [.01, .05, .1, .15])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1.2 creamos un evaluador__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1. creamos un cross validator que definir√° el mejor modelo__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CrossValidator(\n",
    "                    estimator=als,\n",
    "                    estimatorParamMaps=param_grid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1.4 Entrenamos el modelo__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/01 17:58:42 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/04/01 17:58:42 WARN InstanceBuilder$NativeBLAS: Failed to load implementation from:dev.ludovic.netlib.blas.ForeignLinkerBLAS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function JavaWrapper.__del__ at 0x7fb265c62b90>          \n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nicoudin/spark/spark-3.3.2-bin-hadoop3/python/pyspark/ml/wrapper.py\", line 53, in __del__\n",
      "    if SparkContext._active_spark_context and self._java_obj is not None:\n",
      "AttributeError: 'ALS' object has no attribute '_java_obj'\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model = cv.fit(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1.5 Evaluamos el modelo y buscamos el mejor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'RegressionEvaluator' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mbestModel\n\u001b[1;32m      2\u001b[0m testPrediction \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mtransform(df_test)\n\u001b[0;32m----> 3\u001b[0m RMSE \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtestPrediction\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'RegressionEvaluator' object is not callable"
     ]
    }
   ],
   "source": [
    "best_model = model.bestModel\n",
    "testPrediction = best_model.transform(df_test)\n",
    "RMSE = evaluator(testPrediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El mejor modelo que obtuvimos es de: print(RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3.1.6 Hacemos recomenaciones__\n",
    "\n",
    "Usando .recommended(n) lo que obtenemos es el top N de las recomenaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
