{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Creamos una SparSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "            .appName('Test')\\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Leemos un archivo .CSV para crear un __DataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/mnt/d/Proyectos/Tutorial-SparkAWS/data/StudentData.csv\"\n",
    "df = spark.read\\\n",
    "    .option(\"header\", \"True\") \\\n",
    "        .csv(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Aplicamos una __Accion__sobre el __DataFrame__ para mostrar su contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   41|Claude Panos_Judi...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Trabajamos con Esquemas\n",
    "\n",
    "2.1 Mostramos el esquema de DF anterior __Vemos que todo es string__ y no es lo que queremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Inferimos el Esquema usando __\".option(\"inferSchema\", True)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: integer (nullable = true)\n",
      " |-- marks: integer (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"Header\",\"True\").option(\"inferSchema\", True).csv(PATH)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Especificar esquema de forma manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   41|Claude Panos_Judi...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: integer (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType \n",
    "\n",
    "schema_a = StructType ([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"course\", StringType(), True),\n",
    "    StructField(\"roll\", StringType(), True),\n",
    "    StructField(\"marks\", IntegerType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.schema(schema_a).option(\"header\",True).csv(PATH)\n",
    "df.show(5)\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Usar **Kwargs en Spark\n",
    "\n",
    "Se usa para no tener tantos __.option()__ anidados remplazandolo por un unico __.options()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB| 2984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(inferSchema=True, Header=True, delimiter=\",\").csv(PATH)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Spark DF from RDDs\n",
    "\n",
    "Primero creamos un RDD y Luego lo pasamos a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName('Test_rdd').setMaster(\"local[*]\")\n",
    "spark_rdd = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/mnt/d/Proyectos/Tutorial-SparkAWS/data/StudentData.csv\"\n",
    "\n",
    "rdd = spark_rdd.textFile(PATH)\n",
    "header = rdd.first()\n",
    "rdd_data = rdd.filter(lambda x: x != header)\n",
    "#print(rdd_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28,\n",
       " 'Female',\n",
       " 'Hubert Oliveras',\n",
       " 'DB',\n",
       " '02984',\n",
       " 59,\n",
       " 'Annika Hoffman_Naoma Fritts@OOP.com']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data_split = rdd_data.map(lambda x:x.split(\",\"))\n",
    "rdd_data_f = rdd_data_split.map(lambda x: [int(x[0]), x[1], x[2], x[3], x[4], int(x[5]), x[6]])\n",
    "rdd_data_f.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Convertimos el __Rdd__ en un __DataFrame__ usando el Header que sacamos el __Rdd__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_headers = header.split(\",\")\n",
    "df = rdd_data_f.toDF(lista_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   41|Claude Panos_Judi...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: long (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Como el esquema no se puede inferir, lo que hacemos es crear nuestro propio esquema, pero en lugar de usar la __transformacion rdd.toDF()__ usamos __spark.createDataFrame(rdd, schema=)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: integer (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "schema_rdd = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"course\", StringType(), True),\n",
    "    StructField(\"roll\", StringType(), True),\n",
    "    StructField(\"marks\", IntegerType(), True),\n",
    "    StructField(\"email\", StringType(), True)\n",
    "])\n",
    "\n",
    "mi_df = spark.createDataFrame(rdd_data_f, schema=schema_rdd)\n",
    "print(mi_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Seleccion de columnas\n",
    "\n",
    "5.1 Notaci√≥n directa, especificando la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|gender|\n",
      "+---+------+\n",
      "| 28|Female|\n",
      "| 29|Female|\n",
      "+---+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mi_df.select(\"age\", \"gender\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Usando __dot notation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|age|               email|\n",
      "+---+--------------------+\n",
      "| 28|Annika Hoffman_Na...|\n",
      "| 29|Margene Moores_Ma...|\n",
      "+---+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.age, df.email).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Usando __col()__\n",
    "\n",
    "Es una funcion dentro de la libreria __pyspark.sql.functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|gender|\n",
      "+---+------+\n",
      "| 28|Female|\n",
      "| 29|Female|\n",
      "| 28|  Male|\n",
      "| 29|Female|\n",
      "| 28|  Male|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.select(col(\"age\"), col(\"gender\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 Mostrar todas las columnas usando __*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5 Select de las columnas usando Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+--------------------+\n",
      "|course| roll|marks|               email|\n",
      "+------+-----+-----+--------------------+\n",
      "|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "|    PF|21267|   45|Jeannetta Golden_...|\n",
      "|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "+------+-----+-----+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.columns[3:]).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.6 Podemos combinar todo lo anterior"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
