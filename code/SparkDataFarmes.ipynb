{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Creamos una SparSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/01 17:45:03 WARN Utils: Your hostname, DESKTOP-SLEQT56 resolves to a loopback address: 127.0.1.1; using 172.25.13.138 instead (on interface eth0)\n",
      "24/03/01 17:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/01 17:45:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/03/01 17:45:07 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "        .master(\"local[*]\")\\\n",
    "            .appName('Test')\\\n",
    "                .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Leemos un archivo .CSV para crear un __DataFrame__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/mnt/d/Proyectos/Tutorial-SparkAWS/data/StudentData.csv\"\n",
    "df = spark.read\\\n",
    "    .option(\"header\", \"True\") \\\n",
    "        .csv(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Aplicamos una __Accion__sobre el __DataFrame__ para mostrar su contenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   41|Claude Panos_Judi...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Trabajamos con Esquemas\n",
    "\n",
    "2.1 Mostramos el esquema de DF anterior __Vemos que todo es string__ y no es lo que queremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Inferimos el Esquema usando __\".option(\"inferSchema\", True)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: integer (nullable = true)\n",
      " |-- marks: integer (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"Header\",\"True\").option(\"inferSchema\", True).csv(PATH)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Especificar esquema de forma manual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   41|Claude Panos_Judi...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: integer (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType \n",
    "\n",
    "schema_a = StructType ([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"course\", StringType(), True),\n",
    "    StructField(\"roll\", StringType(), True),\n",
    "    StructField(\"marks\", IntegerType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.schema(schema_a).option(\"header\",True).csv(PATH)\n",
    "df.show(5)\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Usar **Kwargs en Spark\n",
    "\n",
    "Se usa para no tener tantos __.option()__ anidados remplazandolo por un unico __.options()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB| 2984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(inferSchema=True, Header=True, delimiter=\",\").csv(PATH)\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Spark DF from RDDs\n",
    "\n",
    "Primero creamos un RDD y Luego lo pasamos a DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName('Test_rdd').setMaster(\"local[*]\")\n",
    "spark_rdd = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/mnt/d/Proyectos/Tutorial-SparkAWS/data/StudentData.csv\"\n",
    "\n",
    "rdd = spark_rdd.textFile(PATH)\n",
    "header = rdd.first()\n",
    "rdd_data = rdd.filter(lambda x: x != header)\n",
    "#print(rdd_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28,\n",
       " 'Female',\n",
       " 'Hubert Oliveras',\n",
       " 'DB',\n",
       " '02984',\n",
       " 59,\n",
       " 'Annika Hoffman_Naoma Fritts@OOP.com']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_data_split = rdd_data.map(lambda x:x.split(\",\"))\n",
    "rdd_data_f = rdd_data_split.map(lambda x: [int(x[0]), x[1], x[2], x[3], x[4], int(x[5]), x[6]])\n",
    "rdd_data_f.first()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Convertimos el __Rdd__ en un __DataFrame__ usando el Header que sacamos el __Rdd__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_headers = header.split(\",\")\n",
    "df = rdd_data_f.toDF(lista_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   41|Claude Panos_Judi...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: long (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: long (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Como el esquema no se puede inferir, lo que hacemos es crear nuestro propio esquema, pero en lugar de usar la __transformacion rdd.toDF()__ usamos __spark.createDataFrame(rdd, schema=)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: integer (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "schema_rdd = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"course\", StringType(), True),\n",
    "    StructField(\"roll\", StringType(), True),\n",
    "    StructField(\"marks\", IntegerType(), True),\n",
    "    StructField(\"email\", StringType(), True)\n",
    "])\n",
    "\n",
    "mi_df = spark.createDataFrame(rdd_data_f, schema=schema_rdd)\n",
    "print(mi_df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Seleccion de columnas\n",
    "\n",
    "5.1 Notación directa, especificando la columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|gender|\n",
      "+---+------+\n",
      "| 28|Female|\n",
      "| 29|Female|\n",
      "+---+------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mi_df.select(\"age\", \"gender\").show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2 Usando __dot notation__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|age|               email|\n",
      "+---+--------------------+\n",
      "| 28|Annika Hoffman_Na...|\n",
      "| 29|Margene Moores_Ma...|\n",
      "+---+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.age, df.email).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Usando __col()__\n",
    "\n",
    "Es una funcion dentro de la libreria __pyspark.sql.functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|age|gender|\n",
      "+---+------+\n",
      "| 28|Female|\n",
      "| 29|Female|\n",
      "| 28|  Male|\n",
      "| 29|Female|\n",
      "| 28|  Male|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.select(col(\"age\"), col(\"gender\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 Mostrar todas las columnas usando __*__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.5 Select de las columnas usando Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+--------------------+\n",
      "|course| roll|marks|               email|\n",
      "+------+-----+-----+--------------------+\n",
      "|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "|    PF|21267|   45|Jeannetta Golden_...|\n",
      "|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "+------+-----+-----+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df.columns[3:]).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.6 Podemos combinar todo lo anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+\n",
      "|age|               email|\n",
      "+---+--------------------+\n",
      "| 28|Annika Hoffman_Na...|\n",
      "| 29|Margene Moores_Ma...|\n",
      "| 28|Jeannetta Golden_...|\n",
      "| 29|Billi Clore_Mitzi...|\n",
      "+---+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col(\"age\"), df.columns[-1]).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. WithColumn()\n",
    "\n",
    "6.1 Ejemplo de Casteo de una columna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+-----+\n",
      "|age|gender|            name|course| roll|marks|               email|roll2|\n",
      "+---+------+----------------+------+-----+-----+--------------------+-----+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...| 2984|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|12899|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|21267|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|32877|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   41|Claude Panos_Judi...|41487|\n",
      "+---+------+----------------+------+-----+-----+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"roll2\", col(\"roll\").cast(\"Integer\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Ejemplo de manipulacion de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+------+\n",
      "|age|gender|            name|course| roll|marks|               email|marks2|\n",
      "+---+------+----------------+------+-----+-----+--------------------+------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|    64|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|    67|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|    50|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|    34|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   41|Claude Panos_Judi...|    46|\n",
      "+---+------+----------------+------+-----+-----+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.withColumn(\"marks2\", col(\"marks\") + 5).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 Crear un valor constante\n",
    "\n",
    "Con .withColumn se puede crear un valor constante, pero hay que __especificarlo con la funcion lit de .sql.functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+----+\n",
      "|age|gender|            name|course| roll|marks|               email|pais|\n",
      "+---+------+----------------+------+-----+-----+--------------------+----+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...| ARG|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...| ARG|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...| ARG|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...| ARG|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   41|Claude Panos_Judi...| ARG|\n",
      "+---+------+----------------+------+-----+-----+--------------------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "\n",
    "df.withColumn('pais',lit('ARG')).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.4 Concatenacion de .withColumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   69|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   72|Margene Moores_Ma...|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   55|Jeannetta Golden_...|\n",
      "| 29|Female|    Elenore Choy|    DB|32877|   39|Billi Clore_Mitzi...|\n",
      "| 28|  Male|  Sheryll Towler|   DSA|41487|   51|Claude Panos_Judi...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.withColumn('marks', col('marks') - 10).withColumn('marks', col('marks') + 20).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. withColumnRename\n",
    "\n",
    "Lo usamos para cambiar el nombre de una columna y generar un nuevo __DF__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+----------------+------+-----+-----+--------------------+\n",
      "|edad|gender|            name|course| roll|marks|               email|\n",
      "+----+------+----------------+------+-----+-----+--------------------+\n",
      "|  28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "|  29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "|  28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|\n",
      "|  29|Female|    Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "+----+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_rename = df.withColumnRenamed(\"age\", \"edad\")\n",
    "df_rename.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.1 Si queremos cambiar el nombre de una variable en tiempo de ejecución usamos __.alias()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|Age|\n",
      "+---+\n",
      "| 28|\n",
      "| 29|\n",
      "| 28|\n",
      "| 29|\n",
      "| 28|\n",
      "+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df_rename.select(col(\"edad\").alias(\"Age\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Filter en __DataFrames__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------------+------+------+-----+--------------------+\n",
      "|age|gender|           name|course|  roll|marks|               email|\n",
      "+---+------+---------------+------+------+-----+--------------------+\n",
      "| 28|Female|Hubert Oliveras|    DB| 02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|   Elenore Choy|    DB| 32877|   29|Billi Clore_Mitzi...|\n",
      "| 29|  Male|Ernest Rossbach|    DB|111449|   53|Maybell Duguay_Ab...|\n",
      "| 28|Female| Latia Vanhoose|    DB|122502|   27|Latia Vanhoose_Mi...|\n",
      "| 29|Female| Latia Vanhoose|    DB|152159|   27|Claude Panos_Sant...|\n",
      "+---+------+---------------+------+------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---+------+---------------+------+------+-----+--------------------+\n",
      "|age|gender|           name|course|  roll|marks|               email|\n",
      "+---+------+---------------+------+------+-----+--------------------+\n",
      "| 28|Female|Hubert Oliveras|    DB| 02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|   Elenore Choy|    DB| 32877|   29|Billi Clore_Mitzi...|\n",
      "| 29|  Male|Ernest Rossbach|    DB|111449|   53|Maybell Duguay_Ab...|\n",
      "| 28|Female| Latia Vanhoose|    DB|122502|   27|Latia Vanhoose_Mi...|\n",
      "| 29|Female| Latia Vanhoose|    DB|152159|   27|Claude Panos_Sant...|\n",
      "+---+------+---------------+------+------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.filter(col(\"course\")=='DB').show(5)\n",
    "df.filter(df.course == \"DB\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.2 Condición multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+------+-----+--------------------+\n",
      "|age|gender|            name|course|  roll|marks|               email|\n",
      "+---+------+----------------+------+------+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB| 02984|   59|Annika Hoffman_Na...|\n",
      "| 29|  Male| Ernest Rossbach|    DB|111449|   53|Maybell Duguay_Ab...|\n",
      "| 28|Female|Mickey Cortright|    DB|192537|   62|Ernest Rossbach_M...|\n",
      "| 28|Female|     Anna Santos|    DB|311589|   79|Celeste Lollis_Mi...|\n",
      "| 29|  Male|    Paris Hutton|    DB|481229|   57|Clementina Menke_...|\n",
      "+---+------+----------------+------+------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(\n",
    "            (df.course == \"DB\") & (df.marks > 50)\n",
    "        ).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.3 Funcionalidad __isin()__ para condiciones múltiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "l_courses = [\"DB\", \"Cloud\", \"OOP\"]\n",
    "df.filter(col(\"course\").isin(l_courses)).show(2)\n",
    "df.filter(df.course.isin(l_courses)).show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.4 Condición __startsWith()_\n",
    "\n",
    "La usamos para determinar cuando una cadena comienza con una determinada letra co caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------------+------+-----+-----+--------------------+\n",
      "|age|gender|           name|course| roll|marks|               email|\n",
      "+---+------+---------------+------+-----+-----+--------------------+\n",
      "| 28|Female|Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|   Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "+---+------+---------------+------+-----+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---+------+---------------+------+-----+-----+--------------------+\n",
      "|age|gender|           name|course| roll|marks|               email|\n",
      "+---+------+---------------+------+-----+-----+--------------------+\n",
      "| 28|Female|Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|   Elenore Choy|    DB|32877|   29|Billi Clore_Mitzi...|\n",
      "+---+------+---------------+------+-----+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.filter(df.course.startswith(\"D\")).show(2)\n",
    "df.filter(col(\"course\").startswith(\"D\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.5 Filtro con __.contains()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------------+------+------+-----+--------------------+\n",
      "|age|gender|        name|course|  roll|marks|               email|\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "| 29|Female|Elenore Choy|    DB| 32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|Elenore Choy|    PF|422704|   66|Marylee Capasso_N...|\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "|age|gender|        name|course|  roll|marks|               email|\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "| 29|Female|Elenore Choy|    DB| 32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|Elenore Choy|    PF|422704|   66|Marylee Capasso_N...|\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.name.contains(\"Eleno\")).show(2)\n",
    "df.filter(col(\"name\").contains(\"Eleno\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8.6 Filtro con __.like()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+------------+------+------+-----+--------------------+\n",
      "|age|gender|        name|course|  roll|marks|               email|\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "| 29|Female|Elenore Choy|    DB| 32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|Elenore Choy|    PF|422704|   66|Marylee Capasso_N...|\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "|age|gender|        name|course|  roll|marks|               email|\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "| 29|Female|Elenore Choy|    DB| 32877|   29|Billi Clore_Mitzi...|\n",
      "| 28|  Male|Elenore Choy|    PF|422704|   66|Marylee Capasso_N...|\n",
      "+---+------+------------+------+------+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "df.filter(df.name.like(\"%Ele%\")).show(2)\n",
    "df.filter(col(\"name\").like(\"%Ele%\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Spark Ejercicio rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, lit\n",
    "from pyspark.sql .types import StructField, StructType, IntegerType, StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"course\", StringType(), True),\n",
    "    StructField(\"roll\", StringType(), True),\n",
    "    StructField(\"marks\", IntegerType(), True),\n",
    "    StructField(\"emails\", StringType(), True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|\n",
      "+---+------+----------------+------+-----+-----+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.options(header=True, schema=schema).csv(\"/mnt/d/Proyectos/Tutorial-SparkAWS/data/StudentData.csv\")\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crear una nueva columna __total marks__ con el valor 120\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"totalMarks\", lit(120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crear una columna __total mark avg__ para cada alumno con la formula \n",
    "__(marks/total_marks)*100__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"avg\", col(\"marks\")/col(\"totalMarks\") * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Filtrar los estudiantes con AVG > 80% in __OOP__\n",
    "4. Filtrar los estudiantes con AVG > 60% in __CLOUD__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oop = df.filter(\n",
    "                    (df.avg>=80) & (df.course == \"OOP\") \n",
    "                )\n",
    "                 \n",
    "df_cloud =  df.filter(               \n",
    "                    (col(\"avg\")>= 60) & (col(\"course\")==\"Cloud\")\n",
    "                    )\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Mostrar los nombres y notas de __3__ y __4__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          name|marks|\n",
      "+--------------+-----+\n",
      "| Kizzy Brenner|   96|\n",
      "|Jenna Montague|   98|\n",
      "+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+------------+-----+\n",
      "|        name|marks|\n",
      "+------------+-----+\n",
      "|Claude Panos|   85|\n",
      "| Billi Clore|   76|\n",
      "+------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_oop.select(col(\"name\"), col(\"marks\")).show(2)\n",
    "df_cloud.select(col(\"name\"), col(\"marks\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Funciones SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.1 Distinct y count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|gender|age|\n",
      "+------+---+\n",
      "|  Male| 29|\n",
      "|  Male| 28|\n",
      "|Female| 28|\n",
      "|Female| 29|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"gender\", \"age\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10.2 dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+----------------+------+-----+-----+--------------------+----------+------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|totalMarks|               avg|\n",
      "+---+------+----------------+------+-----+-----+--------------------+----------+------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|       120|49.166666666666664|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|       120| 51.66666666666667|\n",
      "| 28|  Male|  Celeste Lollis|    PF|21267|   45|Jeannetta Golden_...|       120|              37.5|\n",
      "| 29|  Male|  Cordie Harnois|   OOP|92882|   51|Judie Chipps_Clem...|       120|              42.5|\n",
      "+---+------+----------------+------+-----+-----+--------------------+----------+------------------+\n",
      "\n",
      "+---+------+----------------+------+-----+-----+--------------------+----------+------------------+\n",
      "|age|gender|            name|course| roll|marks|               email|totalMarks|               avg|\n",
      "+---+------+----------------+------+-----+-----+--------------------+----------+------------------+\n",
      "| 28|Female| Hubert Oliveras|    DB|02984|   59|Annika Hoffman_Na...|       120|49.166666666666664|\n",
      "| 29|Female|Toshiko Hillyard| Cloud|12899|   62|Margene Moores_Ma...|       120| 51.66666666666667|\n",
      "+---+------+----------------+------+-----+-----+--------------------+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropDuplicates([\"gender\",\"age\"]).show()\n",
    "df.dropDuplicates([\"age\"]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. Spark Ejercicio rápido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: string (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"course\", StringType(), True),\n",
    "    StructField(\"roll\", StringType(), True),\n",
    "    StructField(\"marks\", IntegerType(), True),\n",
    "    StructField(\"emails\", StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.options(schema=schema, header=True).csv(\"/mnt/d/Proyectos/Tutorial-SparkAWS/data/StudentData.csv\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solucion 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.select(\"age\", \"gender\", \"course\").distinct()\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solucion 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropDuplicates([\"gender\", \"age\", \"course\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. .sort() u .orderBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+--------------+------+-------+-----+--------------------+\n",
      "|age|gender|          name|course|   roll|marks|               email|\n",
      "+---+------+--------------+------+-------+-----+--------------------+\n",
      "| 28|Female|Melani Engberg| Cloud|1872667|   99|Alberta Freund_Ni...|\n",
      "| 28|  Male|   Niki Klimek|   DSA|5172507|   99|Marylee Capasso_E...|\n",
      "| 28|Female|  Judie Chipps|   OOP|5451977|   99|Tamera Blakley_Mi...|\n",
      "| 28|Female|Jalisa Swenson|   MVC|5712033|   99|Dustin Feagins_Hu...|\n",
      "+---+------+--------------+------+-------+-----+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(col('age').asc(), col('marks').desc()).show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Spark ejercicio rapido - Sort() u orderBy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructField, StructType, IntegerType, StringType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "#employee_name,department,state,salary,age,bonus\n",
    "\n",
    "schema = StructType([\n",
    "    StructField('employee_name', StringType(), True),\n",
    "    StructField('department', StringType(), True),\n",
    "    StructField('state', StringType(), True),\n",
    "    StructField('salary', IntegerType(), True),\n",
    "    StructField('age', IntegerType(), True),\n",
    "    StructField('bonus', IntegerType(), True),\n",
    "])\n",
    "\n",
    "df_emp = spark.read.options(schema=schema, header = True).csv(\"/mnt/d/Proyectos/Tutorial-SparkAWS/data/OfficeData.csv\")\n",
    "df_emp.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Crear un DF ordernado por la columna __bonus__ de forma ascendente\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|        James|     Sales|   NY| 90000| 34|10000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|         Jeff| Marketing|   CA| 80000| 25|18000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.select(\"*\").sort(col(\"bonus\").asc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Crear un DF ordenado por las columnas __age__ y __salary__ en orden descendente y ascendente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.select(\"*\").sort(col(\"age\").desc(), col(\"salary\").asc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Crear un DF ordenado por __age__ __bonus__ y __salario__ en orden descendente, descentente y ascendente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|      Michael|     Sales|   NY| 86000| 56|20000|\n",
      "|          Jen|   Finance|   NY| 79000| 53|15000|\n",
      "|        Kumar| Marketing|   NY| 91000| 50|21000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_emp.select(\"*\").sort(col(\"age\").desc(), col(\"bonus\").desc(), col(\"salary\").asc()).show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. GroupBy en DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- course: string (nullable = true)\n",
      " |-- roll: string (nullable = true)\n",
      " |-- marks: integer (nullable = true)\n",
      " |-- emails: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "\n",
    "schemas = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"course\", StringType(), True),\n",
    "    StructField(\"roll\", StringType(), True),\n",
    "    StructField(\"marks\", IntegerType(), True),\n",
    "    StructField(\"emails\", StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.read.schema(schemas).option(\"header\",\"True\").csv(\"/mnt/d/Proyectos/Tutorial-SparkAWS/data/StudentData.csv\")\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|gender|count|\n",
      "+------+-----+\n",
      "|Female|  501|\n",
      "|  Male|  499|\n",
      "+------+-----+\n",
      "\n",
      "+------+----------+\n",
      "|gender|sum(marks)|\n",
      "+------+----------+\n",
      "|Female|     29636|\n",
      "|  Male|     30461|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"gender\").count().show()\n",
    "df.groupBy(\"gender\").sum(\"marks\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
